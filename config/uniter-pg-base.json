{
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.01,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 28996,

  "add_layer_norm_before_adapter": true,
  "add_layer_norm_after_adapter": true,
  "non_linearity":"relu",
  "reduction_factor":2,
  "add_adapter_in_feed_forward":true,
  "add_adapter_in_self_attention":true,
  "residual_before_ln":true,
  "query_before_ln":false,
  "hidden_dim":128,
  "intrinsic_dim":100,
  "normalize_intrinsic_projections":false,
  "intrinsic_projection":"random",

  "use_single_adapter":false,
  "use_fusion":false,
  "use_gate":true,
  "tasks":["itm_tdt","mlm","vcr_tdt"],

  "key":true,
  "query":true,
  "value":true,
  "query_before_ln":false,
  "regularization":true,
  "residual_before":false,
  "temperature":false,
  "value_before_softmax":true,
  "value_initialized":true,
  "use_person_ids":false,
  "m_rate":0.5,
  "kl_rate":1,
  "maxg":0
}
